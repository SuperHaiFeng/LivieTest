//
//  ZZCaptureController.m
//  LiveTest
//
//  Created by å¿—æ–¹ on 17/3/23.
//  Copyright Â© 2017å¹´ å¿—æ–¹. All rights reserved.
//

#import "ZZCaptureController.h"
#import <AVFoundation/AVFoundation.h>
#import <GPUImage.h>
#import "GPUImageBeautifyFilter.h"
#import "H264Encoder.h"
#import "AACEncoder.h"
#import "ZZGiftItem.h"
#import "ZZUserItem.h"
#import "ZZGiftAnimView.h"

@interface ZZCaptureController ()<AVCaptureVideoDataOutputSampleBufferDelegate,AVCaptureAudioDataOutputSampleBufferDelegate,H264EncoderDelegate>
/** å½•åˆ¶ä¼šè¯ */
@property(nonatomic, strong) AVCaptureSession *captureSession;
/** å½“å‰æ‹æ‘„è®¾å¤‡æ‘„åƒå¤´ */
@property(nonatomic, strong) AVCaptureDeviceInput *currentVideoDeviceInput;
/** ç„¦ç‚¹å…‰æ ‡å›¾ç‰‡ */
@property(nonatomic, weak) UIImageView *focusCursorImageView;
/** è§†é¢‘é¢„è§ˆå›¾å±‚ */
@property(nonatomic, weak) AVCaptureVideoPreviewLayer *previedLayer;
/** å½•åˆ¶è¾“å…¥è¾“å‡ºè¿æ¥ */
@property(nonatomic, weak) AVCaptureConnection *videoConnection;
@property(nonatomic,strong) UIButton *backBtn;
@property(nonatomic, strong) UIButton *exchgeCapture;
@property(nonatomic, strong) UIButton *clickUpvote;
@property(nonatomic, strong) UIButton *giftBtn;
/** ç¾é¢œå¼€å…³ */
@property(nonatomic, strong) UISwitch *on_off;

/** ç¾é¢œç›¸æœº */
@property(nonatomic, strong) GPUImageVideoCamera *videoCamera;
/** ç¾é¢œåçš„å›¾å±‚ */
@property(nonatomic, weak) GPUImageView *captureVideoPreview;

@property(nonatomic, weak) GPUImageBilateralFilter *bilateralFilter;
@property(nonatomic, weak) GPUImageBrightnessFilter *brightnessFilter;
/** éŸ³è§†é¢‘ç¼–ç  */
@property(nonatomic, strong) H264Encoder *h264Encoder;
@property(nonatomic, strong) AACEncoder *aacEncoder;
@property(nonatomic, copy) NSString *h264File;
@property(nonatomic, strong) NSFileHandle *fileHandle;

/** ç¤¼ç‰©åŠ¨ç”» */
@property(nonatomic, strong) NSMutableArray *giftQueue;
@property(nonatomic, strong) NSMutableArray *giftAnimViews;
@property(nonatomic, strong) NSMutableArray *positions;

@end

@implementation ZZCaptureController

/** æ‡’åŠ è½½èšç„¦è§†å›¾ */
-(UIImageView *) focusCursorImageView {
    if (_focusCursorImageView == nil) {
        UIImageView *imageView = [[UIImageView alloc] initWithImage:[UIImage imageNamed:@"focus"]];
        _focusCursorImageView = imageView;
        [self.view addSubview:_focusCursorImageView];
    }
    return _focusCursorImageView;
}

- (void)viewDidLoad {
    [super viewDidLoad];
    self.title = @"è§†é¢‘é‡‡é›†";
    self.view.backgroundColor = [UIColor whiteColor];
    
    [self.navigationController.navigationBar setHidden:YES];
    
    [self setView];
    [self setupCaptureVideo];
    
    [self setupVideoCamera];
//    [self setupAdjustCamera];
    
}
-(void) setView {
    self.backBtn = [UIButton buttonWithType:UIButtonTypeSystem];
    [self.backBtn addTarget:self action:@selector(backAction) forControlEvents:UIControlEventTouchUpInside];
    [self setBtn:self.backBtn withFrame:CGRectMake(10, 25, 40, 40) withTitle:@"ğŸ”™"];
    
    self.exchgeCapture = [UIButton buttonWithType:UIButtonTypeSystem];
    [self.exchgeCapture addTarget:self action:@selector(exchangeAction) forControlEvents:UIControlEventTouchUpInside];
    [self setBtn:self.exchgeCapture withFrame:CGRectMake(kScreenWidth - 50, 25, 40, 40) withTitle:@"ğŸ‘â€ğŸ—¨"];
    
    self.giftBtn = [UIButton buttonWithType:UIButtonTypeSystem];
    [self.giftBtn addTarget:self action:@selector(sendGiftAction) forControlEvents:UIControlEventTouchUpInside];
    [self setBtn:self.giftBtn withFrame:CGRectMake(10, kScreenHeight - 150, 40, 40) withTitle:@"ğŸ’"];
    
    self.on_off = [[UISwitch alloc] initWithFrame:CGRectMake(kScreenWidth - 60, 80, 50, 40)];
    [self.on_off addTarget:self action:@selector(on_offAction:) forControlEvents:UIControlEventTouchUpInside];
    [self.view addSubview:self.on_off];
    
    UISlider *slider1 = [[UISlider alloc] initWithFrame:CGRectMake(30, kScreenHeight - 100, kScreenWidth - 60, 30)];
    [slider1 addTarget:self action:@selector(brightnessFilter:) forControlEvents:UIControlEventTouchUpInside];
    [self.view addSubview:slider1];
    
    UISlider *slider2 = [[UISlider alloc] initWithFrame:CGRectMake(30, kScreenHeight - 60, kScreenWidth - 60, 30)];
    [slider2 addTarget:self action:@selector(bilateralFilter:) forControlEvents:UIControlEventTouchUpInside];
    [self.view addSubview:slider2];
    
    self.clickUpvote = [UIButton buttonWithType:UIButtonTypeSystem];
    [self setBtn:self.clickUpvote withFrame:CGRectMake(kScreenWidth - 50, kScreenHeight - 150, 40, 40) withTitle:@"ğŸ’•"];
    [self.clickUpvote addTarget:self action:@selector(clickUpvoteAction) forControlEvents:UIControlEventTouchUpInside];
    
    
}
-(void) clickUpvoteAction {
    [self setupVoteLayer];
}
-(void) sendGiftAction {
    
}
#pragma mark - è®¾ç½®ç‚¹èµLayer 
-(void) setupVoteLayer {
    CALayer *layer = [CALayer layer];
    layer.contents = (id)[UIImage imageNamed:@"2.png"].CGImage;
    [self.view.layer addSublayer:layer];
    layer.bounds = CGRectMake(0, 0, 30, 30);
    layer.position = CGPointMake(kScreenWidth - 30, kScreenHeight - 130);
    
    [self setupAnim:layer];
}
//è®¾ç½®ç‚¹èµlayeråŠ¨ç”»
-(void) setupAnim : (CALayer *) layer {
    [CATransaction begin];
    
    [CATransaction setCompletionBlock:^{
        [layer removeAllAnimations];
        [layer removeFromSuperlayer];
    }];
    
    //åˆ›å»ºbasicåŠ¨ç”»
    CABasicAnimation *alphaAnim = [CABasicAnimation animation];
    alphaAnim.keyPath = @"alpha";
    alphaAnim.fromValue = @0;
    alphaAnim.toValue = @1;
    
    //è·¯å¾„åŠ¨ç”»
    CAKeyframeAnimation *pathAnim = [CAKeyframeAnimation animation];
    pathAnim.keyPath = @"position";
    pathAnim.path = [self animPath:layer].CGPath;
    
    //åˆ›å»ºåŠ¨ç”»ç»„
    CAAnimationGroup *group = [CAAnimationGroup animation];
    group.animations = @[alphaAnim,pathAnim];
    group.duration = 4;
    [layer addAnimation:group forKey:nil];
    
    [CATransaction commit];
}

-(UIBezierPath *) animPath : (CALayer *) layer {
    
    UIBezierPath *path = [UIBezierPath bezierPath];
    
    CGFloat y = kScreenHeight - 130;
    CGFloat x = 30;
    while (y > 0) {
        if (y == kScreenHeight - 130) {
            [path moveToPoint:CGPointMake(kScreenWidth - x, y)];
        }else{
            if (y <= kScreenHeight - 500) {
                [path moveToPoint:CGPointMake(kScreenWidth - x, y)];
            }else{
                [path addLineToPoint:CGPointMake(kScreenWidth - x, y)];
            }
            
        }
        x = arc4random_uniform(kScreenWidth * 0.3 - 20) + 20;
        y -= 20;
    }
    
    return path;
}

//è®¾ç½®æŒ‰é’®å±æ€§
-(void) setBtn : (UIButton *) button
     withFrame : (CGRect) frame
     withTitle : (NSString *) title {
    button.frame = frame;
    [button setTitle:title forState:UIControlStateNormal];
    [button setTintColor:[UIColor blackColor]];
    button.titleLabel.font = [UIFont boldSystemFontOfSize:20];
    button.layer.cornerRadius = 20;
    button.backgroundColor = [UIColor whiteColor];
    button.alpha = 0.8;
    [self.view addSubview:button];
}
#pragma mark - ç¾é¢œ
-(void) brightnessFilter : (UISlider *) sender {
    _brightnessFilter.brightness = sender.value;
}
#pragma mark - ç£¨çš®
-(void) bilateralFilter : (UISlider *) sender {
    //å€¼è¶Šå°ï¼Œç£¨çš®æ•ˆæœè¶Šå¥½
    CGFloat maxValue = 10;
    [_bilateralFilter setDistanceNormalizationFactor:(maxValue - sender.value)];
}
#pragma mark - è®¾ç½®è‡ªè°ƒèŠ‚ç¾é¢œ
-(void) setupAdjustCamera {
    //åˆ›å»ºè§†é¢‘æº
    //SessionPreset: å±å¹•åˆ†è¾¨ç‡ï¼ŒAVCaptureSessionPresetHighä¼šè‡ªé€‚åº”é«˜åˆ†è¾¨ç‡
    //cameraPositionï¼šæ‘„åƒå¤´æ–¹å‘
    //æœ€å¥½ä½¿ç”¨AVCaptureSessionPresetHigh,ä¼šè‡ªåŠ¨è¯†åˆ«ï¼Œå¦‚æœå¤ªé«˜åˆ†è¾¨ç‡ï¼Œå½“å‰è®¾å¤‡ä¸æ”¯æŒä¼šç›´æ¥æŠ¥é”™
    GPUImageVideoCamera *videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPresetHigh cameraPosition:AVCaptureDevicePositionFront | AVCaptureDevicePositionBack];
    videoCamera.outputImageOrientation = UIInterfaceOrientationPortrait;
    _videoCamera = videoCamera;
    
    //åˆ›å»ºæœ€ç»ˆé¢„è§ˆview
    GPUImageView *captureVideoPreview = [[GPUImageView alloc] initWithFrame:self.view.bounds];
    [self.view insertSubview:captureVideoPreview atIndex:0];
    
    //åˆ›å»ºæ»¤é•œï¼šç£¨çš®ã€ç¾ç™½ã€ç»„åˆæ»¤é•œ
    GPUImageFilterGroup *groupFilter = [[GPUImageFilterGroup alloc] init];
    
    //ç£¨çš®æ»¤é•œ
    GPUImageBilateralFilter *bilateralFilter = [[GPUImageBilateralFilter alloc] init];
    [groupFilter addTarget:bilateralFilter];
    _bilateralFilter = bilateralFilter;
    
    //ç¾ç™½æ»¤é•œ
    GPUImageBrightnessFilter *brightnessFilter = [[GPUImageBrightnessFilter alloc] init];
    [groupFilter addTarget:brightnessFilter];
    _brightnessFilter = brightnessFilter;
    
    //è®¾ç½®æ»¤é•œç»„é“¾
    [bilateralFilter addTarget:brightnessFilter];
    [groupFilter setInitialFilters:@[bilateralFilter]];
    groupFilter.terminalFilter = brightnessFilter;
    
    //è®¾ç½®GPUImageå¤„ç†é“¾ï¼Œä»æ•°æ®æº => æ»¤é•œ = > æœ€ç»ˆç•Œé¢æ•ˆæœ
    [videoCamera addTarget:groupFilter];
    [groupFilter addTarget:captureVideoPreview];
    
    //å¿…é¡»è°ƒç”¨startCameraCapture åº•å±‚æ‰ä¼šæŠŠé‡‡é›†åˆ°çš„è§†é¢‘æºï¼Œæ¸²æŸ“åˆ°GPUImageViewä¸­ï¼Œ
    [videoCamera startCameraCapture];
    
}
#pragma mark - è®¾ç½®å¼€å…³ç¾é¢œ
-(void) setupVideoCamera {
    //åˆ›å»ºè§†é¢‘æº
    //SessionPreset: å±å¹•åˆ†è¾¨ç‡ï¼ŒAVCaptureSessionPresetHighä¼šè‡ªé€‚åº”é«˜åˆ†è¾¨ç‡
    //cameraPositionï¼šæ‘„åƒå¤´æ–¹å‘
    GPUImageVideoCamera *videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPresetHigh cameraPosition:AVCaptureDevicePositionFront | AVCaptureDevicePositionBack];
    videoCamera.outputImageOrientation = UIInterfaceOrientationPortrait;
    _videoCamera = videoCamera;
    
    
    //åˆ›å»ºæœ€ç»ˆé¢„è§ˆview
    GPUImageView *captureVideoPreview = [[GPUImageView alloc] initWithFrame:self.view.bounds];
    
    _captureVideoPreview = captureVideoPreview;
    [self.view insertSubview:_captureVideoPreview atIndex:0];
    //è®¾ç½®å¤„ç†é“¾
    [_videoCamera addTarget:_captureVideoPreview];
    
    //å¿…é¡»è°ƒç”¨startCameraCapture,åº•å±‚æ‰ä¼šæŠŠé‡‡é›†åˆ°çš„è§†é¢‘æºï¼Œæ¸²æŸ“åˆ°GPUImageViewä¸­ï¼Œå°±èƒ½æ˜¾ç¤ºäº†
    //å¼€å§‹é‡‡é›†è§†é¢‘
    [_videoCamera startCameraCapture];
}
-(void) on_offAction : (UISwitch *) sender {
    //åˆ‡æ¢ç¾é¢œæ•ˆæœåŸç†ï¼šç§»é™¤ä¹‹å‰æ‰€æœ‰å¤„ç†é“¾ï¼Œé‡æ–°è®¾ç½®å¤„ç†é“¾
    if (sender.on) {
        //ç§»é™¤ä¹‹å‰æ‰€æœ‰å¤„ç†é“¾
        [_videoCamera removeAllTargets];
        
        //åˆ›å»ºç¾é¢œæ»¤é•œ
        GPUImageBeautifyFilter *beautifyFilter = [[GPUImageBeautifyFilter alloc] init];
        
        //è®¾ç½®GPUImageå¤„ç†é“¾ï¼Œä»æ•°æ®æº => æ»¤é•œ => æœ€ç»ˆç•Œé¢æ•ˆæœ
        [_videoCamera addTarget:beautifyFilter];
        [beautifyFilter addTarget:_captureVideoPreview];
    }else{
        //ç§»é™¤ä¹‹å‰æ‰€æœ‰å¤„ç†é“¾
        [_videoCamera removeAllTargets];
        [_videoCamera addTarget:_captureVideoPreview];
    }
}

-(void) backAction {
    [self.navigationController popViewControllerAnimated:YES];
}
-(void)viewWillDisappear:(BOOL)animated {
    [super viewWillDisappear:animated];
    self.h264Encoder.delegate = nil;
    self.h264Encoder = nil;
    [_captureSession stopRunning];
}
#pragma mark æ•è·éŸ³è§†é¢‘
-(void) setupCaptureVideo {
    //1.åˆ›å»ºæ•è·ä¼šè¯ï¼Œå¿…é¡»è¦å¼ºå¼•ç”¨ï¼Œå¦åˆ™ä¼šè¢«é‡Šæ”¾
    AVCaptureSession *captureSession = [[AVCaptureSession alloc] init];
    _captureSession = captureSession;
    
    //åˆå§‹åŒ–è§†é¢‘ç¼–ç (H264)
    self.h264Encoder = [H264Encoder new];
    [self.h264Encoder initWithConfiguration];
    [self.h264Encoder initEncode:480 height:640];
    self.h264Encoder.delegate = self;
    if ([_captureSession canSetSessionPreset:AVCaptureSessionPreset1280x720]) {
        //è®¾ç½®åˆ†è¾¨ç‡
        _captureSession.sessionPreset = AVCaptureSessionPreset1280x720;
    }
    //2.è·å–æ‘„åƒå¤´è®¾å¤‡ï¼Œé»˜è®¤æ˜¯åç½®æ‘„åƒå¤´
    AVCaptureDevice *videoDevice = [self getVideoDevice:AVCaptureDevicePositionFront];
    
    //åˆå§‹åŒ–éŸ³é¢‘ç¼–ç (AAC)
    self.aacEncoder = [AACEncoder new];
    //3.è·å–å£°éŸ³è®¾å¤‡
    AVCaptureDevice *audioDevice = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeAudio];
    
    //4.åˆ›å»ºå¯¹åº”è§†é¢‘è®¾å¤‡è¾“å…¥å¯¹è±¡
    AVCaptureDeviceInput *videoDeviceInput = [AVCaptureDeviceInput deviceInputWithDevice:videoDevice error:nil];
    _currentVideoDeviceInput = videoDeviceInput;
    
    //5.åˆ›å»ºå¯¹åº”éŸ³é¢‘è®¾å¤‡è¾“å…¥å¯¹è±¡
    AVCaptureDeviceInput *audioDeviceInput = [AVCaptureDeviceInput deviceInputWithDevice:audioDevice error:nil];
    
    //6.æ·»åŠ å›è¯ä¸­(æ³¨æ„ï¼šæœ€å¥½è¦åˆ¤æ–­æ˜¯å¦èƒ½æ·»åŠ è¾“å…¥ï¼Œå›è¯ä¸èƒ½æ·»åŠ ç©ºçš„)
    //6.1 æ·»åŠ è§†é¢‘
    if ([captureSession canAddInput:videoDeviceInput]) {
        [captureSession addInput:videoDeviceInput];
    }
    //6.2 æ·»åŠ éŸ³é¢‘
    if ([captureSession canAddInput:audioDeviceInput]) {
        [captureSession addInput:audioDeviceInput];
    }
    
    //7.è·å–è§†é¢‘æ•°æ®è¾“å‡ºè®¾å¤‡
    AVCaptureVideoDataOutput *videoOutput = [[AVCaptureVideoDataOutput alloc] init];
    //7.1 è®¾ç½®ä»£ç†ï¼Œæ•è·è§†é¢‘æ ·å“æ•°æ®
    // æ³¨æ„ï¼šé˜Ÿåˆ—å¿…é¡»æ˜¯ä¸²è¡Œé˜Ÿåˆ—ï¼Œæ‰èƒ½è·å–åˆ°æ•°æ®ï¼Œè€Œä¸”ä¸èƒ½ä¸ºç©º
    dispatch_queue_t videoQueue = dispatch_queue_create("Video Capture Queue", DISPATCH_QUEUE_SERIAL);
    [videoOutput setSampleBufferDelegate:self queue:videoQueue];
    
    //é…ç½®è¾“å‡ºè§†é¢‘å›¾åƒæ ¼å¼
    NSDictionary *captureSettings = @{(NSString *)kCVPixelBufferPixelFormatTypeKey:@(kCVPixelFormatType_32BGRA)};
    videoOutput.videoSettings = captureSettings;
    videoOutput.alwaysDiscardsLateVideoFrames = YES;
    if ([captureSession canAddOutput:videoOutput]) {
        [captureSession addOutput:videoOutput];
    }
    
    //8. è·å–éŸ³é¢‘æ•°æ®è¾“å‡ºè®¾å¤‡
    AVCaptureAudioDataOutput *audioOutput = [[AVCaptureAudioDataOutput alloc] init];
    //8.2è®¾ç½®ä»£ç†ã€‚æ•è·è§†é¢‘æ ·å“æ•°æ®
    //æ³¨æ„ï¼šé˜Ÿåˆ—å¿…é¡»æ˜¯ä¸²è¡Œé˜Ÿåˆ—ï¼Œæ‰èƒ½è·å–åˆ°æ•°æ®ï¼Œè€Œä¸”ä¸èƒ½ä¸ºç©º
    dispatch_queue_t audioQueue = dispatch_queue_create("Audio Capture Queue", DISPATCH_QUEUE_SERIAL);
    [audioOutput setSampleBufferDelegate:self queue:audioQueue];
    if ([captureSession canAddOutput:audioOutput]) {
        [captureSession addOutput:audioOutput];
    }
    
    //9.è·å–è§†é¢‘è¾“å…¥ä¸è¾“å‡ºè¿æ¥ï¼Œç”¨äºåˆ†è¾¨éŸ³è§†é¢‘æ•°æ®
    _videoConnection = [videoOutput connectionWithMediaType:AVMediaTypeVideo];
    
    //10.æ·»åŠ è§†é¢‘é¢„è§ˆå›¾å±‚
    AVCaptureVideoPreviewLayer *previedLayer = [AVCaptureVideoPreviewLayer layerWithSession:captureSession];
    previedLayer.frame = [UIScreen mainScreen].bounds;
    _previedLayer = previedLayer;
    [self.view.layer insertSublayer:previedLayer atIndex:0];
    
    
    //11. å¯åŠ¨ä¼šè¯
    [captureSession startRunning];
   
    
    NSFileManager *fileManager = [NSFileManager defaultManager];
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSString *documentsDirectory = [paths firstObject];
    
    self.h264File = [documentsDirectory stringByAppendingString:@"lyh.h264"];
    [fileManager removeItemAtPath:self.h264File error:nil];
    [fileManager createFileAtPath:self.h264File contents:nil attributes:nil];
    self.fileHandle = [NSFileHandle fileHandleForWritingAtPath:self.h264File];
    
}

#pragma mark æŒ‡å®šæ‘„åƒå¤´æ–¹å‘è·å–æ‘„åƒå¤´
-(AVCaptureDevice *) getVideoDevice : (AVCaptureDevicePosition) position {
    NSArray *devices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
    for (AVCaptureDevice *device in devices) {
        if (device.position == position) {
            return device;
        }
    }
    return nil;
}

#pragma mark AVCaptureVideoDataOutputSampleBufferDelegate
//è·å–è¾“å…¥è®¾å¤‡æ•°æ®ï¼Œæœ‰å¯èƒ½æ˜¯éŸ³é¢‘æœ‰å¯èƒ½æ˜¯è§†é¢‘
-(void)captureOutput:(AVCaptureOutput *)captureOutput
didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer
      fromConnection:(AVCaptureConnection *)connection{
    
    CMTime pts = CMSampleBufferGetDuration(sampleBuffer);
    double dPTS = (double)(pts.value);
    NSLog(@"PDTS IS%f",dPTS);
    
    //è¿™é‡Œçš„sampleBufferå°±æ˜¯é‡‡é›†åˆ°çš„æ•°æ®äº†ï¼Œä½†ä»–æ˜¯Videoè¿˜æ˜¯Audioçš„æ•°æ®ï¼Œå¾—æ ¹æ®connectionæ¥åˆ¤æ–­
    if (_videoConnection == connection) {
        //å–å¾—å½“å‰è§†é¢‘çš„å°ºå¯¸ä¿¡æ¯
        CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
        NSInteger width = CVPixelBufferGetWidth(pixelBuffer);
        NSInteger height = CVPixelBufferGetHeight(pixelBuffer);
        [self.h264Encoder encode:sampleBuffer];
    }else{
        
        [self.aacEncoder encodeSampleBuffer:sampleBuffer
                            completionBlock:^(NSData *encodedData, NSError *error) {
            if (encodedData) {
                NSLog(@"Audio data (%lu):%@", (unsigned long)encodedData.length,encodedData.description);
#pragma mark - éŸ³é¢‘æ•°æ®ï¼ˆencodedDataï¼‰
                
            }
        }];
    }
}

#pragma mark - H264ç¼–ç delegate
-(void)gotSpsPps:(NSData *)sps
             pps:(NSData *)pps {
    const char bytes[] = "\x00\x00\x00\x01";
    size_t length = sizeof(bytes) - 1;//å­—ç¬¦ä¸²æ–‡å­—å…·æœ‰éšå«çš„å°¾éš'\ 0'

    NSData *ByteHeader = [NSData dataWithBytes:bytes length:length];
    [_fileHandle writeData:ByteHeader];
    [_fileHandle writeData:sps];
    [_fileHandle writeData:ByteHeader];
    [_fileHandle writeData:pps];

}

-(void)gotEncodedData:(NSData *)data
           isKeyFrame:(BOOL)isKeyFrame {
    NSLog(@"Video data (%lu):%@",(unsigned long)data.length,data.description);
    
    if (_fileHandle != NULL) {
        const char bytes[] = "\x00\x00\x00\x01";
        size_t length = sizeof(bytes) - 1;
        NSData *ByteHeader = [NSData dataWithBytes:bytes length:length];
        
#pragma mark - è§†é¢‘æ•°æ®
        [_fileHandle writeData:ByteHeader];
        [_fileHandle writeData:data];
    }
}

#pragma mark - å°†æ•è·çš„è§†é¢‘è½¬æ¢æˆå›¾ç‰‡
-(UIImage *) imageFromSampleBuffer : (CMSampleBufferRef) sampleBuffer {
    //è·å–CMSampleBufferRef çš„medioæ•°æ®
    CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
    
    //åƒç´ ç¼“å†²åŒºçš„é”åŸºåœ°å€
    CVPixelBufferLockBaseAddress(imageBuffer, 0);
    
    //è·å–æ¯ä¸€è¡Œçš„åƒç´ ç¼“å†²åŒºçš„å­—èŠ‚æ•°
    size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);
    
    //è·å–åƒç´ ç¼“å†²åŒºçš„å®½å’Œé«˜
    size_t width = CVPixelBufferGetWidth(imageBuffer);
    size_t height = CVPixelBufferGetHeight(imageBuffer);
    
    //è·å–æ¯ä¸€è¡Œçš„åƒç´ ç¼“å†²åŒºçš„å­—èŠ‚æ•°
    uint8_t *baseAddress = (uint8_t *)malloc(bytesPerRow * height);
    memcpy(baseAddress, CVPixelBufferGetBaseAddress(imageBuffer), bytesPerRow * height);
    
//    size_t bufferSize = CVPixelBufferGetDataSize(imageBuffer);
    
    //åˆ›å»ºä¸€ä¸ªè®¾å¤‡ç›¸å…³çš„RGBé¢œè‰²ç©ºé—´
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    
    //åˆ›å»ºä¸€ä¸ªä½å›¾å›¾å½¢ä¸Šä¸‹æ–‡ä¸æ ·å“ç¼“å†²æ•°æ®
    //æ ¹æ®ä¸Šä¸‹æ–‡ç”»ä¸€ä¸ªä½å›¾çš„å®½åº¦
    //åƒç´ å®½,é«˜åº¦çš„åƒç´ é«˜ã€‚æŒ‡å®šç»„ä»¶çš„æ•°é‡ä¸ºæ¯ä¸ªåƒç´ ç”±â€œç©ºé—´â€
    CGContextRef context = CGBitmapContextCreate(baseAddress, width, height, 8, bytesPerRow, colorSpace, kCGBitmapByteOrder32Big | kCGImageAlphaPremultipliedFirst);
    
    
    //åœ¨ä½å›¾å›¾å½¢ä¸Šä¸‹æ–‡ä¸­åˆ›å»ºä¸€ä¸ªå›¾åƒåƒç´ æ•°æ®
    CGImageRef quartzImage = CGBitmapContextCreateImage(context);
    
    //è§£é”åƒç´ ç¼“å†²åŒº
    CVPixelBufferUnlockBaseAddress(imageBuffer, 0);
    
    //é‡Šæ”¾ä¸Šä¸‹æ–‡å’Œé¢œè‰²ç©ºé—´
    CGContextRelease(context);
    CGColorSpaceRelease(colorSpace);
    
    //ä»Quartzå›¾åƒä¸­åˆ›å»ºä¸€ä¸ªå›¾ç‰‡å¯¹è±¡
    UIImage *image= [UIImage imageWithCGImage:quartzImage scale:1.0 orientation:UIImageOrientationRight];
    //é‡Šæ”¾åƒç´ ç¼“å†²åŒºçš„å­—èŠ‚æ•°
    free(baseAddress);
    //é‡Šæ”¾Quartzå›¾åƒ
    CGImageRelease(quartzImage);
    
    
    
    return image;
}
#pragma mark åˆ‡æ¢æ‘„åƒå¤´
-(void) exchangeAction {
    //è·å–å½“å‰è®¾å¤‡æ–¹å‘
    AVCaptureDevicePosition curPosition = _currentVideoDeviceInput.device.position;
    
    //è·å–éœ€è¦æ”¹å˜çš„æ–¹å‘
    AVCaptureDevicePosition togglePosition = curPosition == AVCaptureDevicePositionFront ? AVCaptureDevicePositionBack : AVCaptureDevicePositionFront;
    
    //è·å–æ”¹å˜çš„æ‘„åƒå¤´çš„è®¾å¤‡
    AVCaptureDevice *toggleDevice = [self getVideoDevice:togglePosition];
    
    //è·å–æ”¹å˜çš„æ‘„åƒå¤´çš„è¾“å…¥è®¾å¤‡
    AVCaptureDeviceInput *toggleDeviceInput = [AVCaptureDeviceInput deviceInputWithDevice:toggleDevice error:nil];
    
    //ç§»é™¤ä¹‹å‰æ‘„åƒå¤´è¾“å…¥è®¾å¤‡
    [_captureSession removeInput:_currentVideoDeviceInput];
    
    //æ·»åŠ æ–°çš„æ‘„åƒå¤´è¾“å…¥è®¾å¤‡
    [_captureSession addInput:toggleDeviceInput];
    
    //è®°å½•å½“å‰æ‘„åƒå¤´è¾“å…¥è®¾å¤‡
    _currentVideoDeviceInput = toggleDeviceInput;
    
}

#pragma mark - ç‚¹å‡»å±å¹•ï¼Œå‡ºç°èšç„¦è§†å›¾
-(void)touchesBegan:(NSSet<UITouch *> *)touches
          withEvent:(UIEvent *)event {
    //è·å–ç‚¹å‡»ä½ç½®
    UITouch *touch = [touches anyObject];
    CGPoint point = [touch locationInView:self.view];
    
    //æŠŠå½“å‰ä½ç½®è½¬æ¢ä¸ºæ‘„åƒå¤´ç‚¹ä¸Šçš„ä½ç½®
    CGPoint cameraPoint = [_previedLayer captureDevicePointOfInterestForPoint:point];
    
    //è®¾ç½®èšç„¦ç‚¹å…‰æ ‡ä½ç½®
    [self setFocusCursorWithPoint:point];
    
    //è®¾ç½®èšç„¦
    [self focusWithMode:AVCaptureFocusModeAutoFocus exposureMode:AVCaptureExposureModeAutoExpose atPoint:cameraPoint];
}

#pragma mark - è®¾ç½®èšç„¦å…‰æ ‡ä½ç½®
/** pointï¼šå…‰æ ‡ä½ç½® */
-(void) setFocusCursorWithPoint : (CGPoint) point {
    self.focusCursorImageView.center = point;
    self.focusCursorImageView.transform = CGAffineTransformMakeScale(1.5, 1.5);
    self.focusCursorImageView.alpha = 1.0;
    [UIView animateWithDuration:1.0 animations:^{
        self.focusCursorImageView.transform = CGAffineTransformIdentity;
    } completion:^(BOOL finished) {
        self.focusCursorImageView.alpha = 0;
    }];
}

#pragma mark - è®¾ç½®èšç„¦
-(void) focusWithMode : (AVCaptureFocusMode) focusMode
         exposureMode : (AVCaptureExposureMode) exposureMode
              atPoint : (CGPoint) point {
    AVCaptureDevice *captureDevice = _currentVideoDeviceInput.device;
    
    //é”å®šé…ç½®
    [captureDevice lockForConfiguration:nil];
    
    //è®¾ç½®èšç„¦
    if ([captureDevice isFocusModeSupported:AVCaptureFocusModeAutoFocus]) {
        [captureDevice setFocusMode:AVCaptureFocusModeAutoFocus];
    }
    if ([captureDevice isFocusPointOfInterestSupported]) {
        [captureDevice setFocusPointOfInterest:point];
    }
    
    //è®¾ç½®æ›å…‰
    if ([captureDevice isExposureModeSupported:AVCaptureExposureModeAutoExpose]) {
        [captureDevice setExposureMode:AVCaptureExposureModeAutoExpose];
    }
    if ([captureDevice isExposurePointOfInterestSupported]) {
        [captureDevice setExposurePointOfInterest:point];
    }
    
    //è§£é”é…ç½®
    [captureDevice unlockForConfiguration];
}

#pragma mark - å‘é€ç¤¼ç‰©

#pragma mark - åˆ¤æ–­å½“å‰æ¥å—çš„ç¤¼ç‰©æ˜¯å¦å±äºè¿å‘ç¤¼ç‰©
-(BOOL) isComboGift : (ZZGiftItem *) gift {
    
    ZZGiftItem *comboGift = nil;
    
    for (ZZGiftItem *giftItem in self.giftQueue) {
        //å¦‚æœæ˜¯è¿å‘ç¤¼ç‰©å°±è®°å½•ä¸‹æ¥
        if (giftItem.giftId == gift.giftId && giftItem.user.ID == gift.user.ID) {
            comboGift = giftItem;
        }
    }
    
    if (comboGift) {//è¿å‘ç¤¼ç‰©æœ‰å€¼
        //ç¤¼ç‰©æ¨¡å‹çš„ç¤¼ç‰©æ€»æ•°+1
        comboGift.giftCount += 1;
        return YES;
    }
    return NO;
    
}
//å¤„ç†åŠ¨ç”»
-(void) handleGiftAnim : (ZZGiftItem *) gift {
    //1 åˆ›å»ºç¤¼ç‰©åŠ¨ç”»çš„view
    ZZGiftAnimView *giftView = [ZZGiftAnimView giftAnimView];
    
    CGFloat h = self.view.bounds.size.height * 0.5;
    CGFloat w = self.view.bounds.size.width;
    
    //å–å‡ºç¤¼ç‰©ä½ç½®
    id position = self.positions.lastObject;
    
    //ä»æ•°ç»„ç§»é™¤ä½ç½®
    [self.positions removeObject:position];
    
    CGFloat y = [position floatValue] * h;
    //2.è®¾ç½®ç¤¼ç‰©viewçš„frame
    giftView.frame = CGRectMake(0, y, w, h);
    
    //3.ä¼ é€’ç¤¼ç‰©æ¨¡å‹
    
    //è®°å½•å½“å‰ä½ç½®
    giftView.tag = [position floatValue];
    
    //æ·»åŠ ç¤¼ç‰©view
    [self.view addSubview:giftView];
    
    __weak typeof(self) weakself = self;
    
    //è®¾ç½®åŠ¨ç”»
    giftView.transform = CGAffineTransformMakeTranslation(-w, 0);
    [UIView animateWithDuration:25 delay:0 usingSpringWithDamping:0.6 initialSpringVelocity:1 options:UIViewAnimationOptionCurveLinear animations:^{
        giftView.transform = CGAffineTransformIdentity;
    } completion:^(BOOL finished) {
        //å¼€å§‹è¿å‡»åŠ¨ç”»
        
    }];
}


-(NSMutableArray *)giftQueue {
    if (_giftQueue == nil) {
        _giftQueue = [NSMutableArray array];
    }
    return _giftQueue;
}
-(NSMutableArray *)giftAnimViews {
    if (_giftAnimViews == nil) {
        _giftAnimViews = [NSMutableArray array];
    }
    return _giftAnimViews;
}
-(NSMutableArray *)positions {
    if (_positions == nil) {
        _positions = [NSMutableArray array];
    }
    return _positions;
}

- (void)didReceiveMemoryWarning {
    [super didReceiveMemoryWarning];
    // Dispose of any resources that can be recreated.
}

/*
#pragma mark - Navigation

// In a storyboard-based application, you will often want to do a little preparation before navigation
- (void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender {
    // Get the new view controller using [segue destinationViewController].
    // Pass the selected object to the new view controller.
}
*/

@end
